
@online{noauthor_resnet101_nodate,
	title = {resnet101 — Torchvision main documentation},
	url = {https://pytorch.org/vision/main/models/generated/torchvision.models.resnet101.html},
	urldate = {2024-01-02},
	keywords = {Conclusion, {TFM}},
}

@online{noauthor_resnet101_nodate-1,
	title = {resnet101 — Torchvision main documentation},
	url = {https://pytorch.org/vision/main/models/generated/torchvision.models.resnet101.html},
	urldate = {2024-01-02},
}

@misc{simonyan_very_2015,
	title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our {ImageNet} Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing {ConvNet} models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	number = {{arXiv}:1409.1556},
	publisher = {{arXiv}},
	author = {Simonyan, Karen and Zisserman, Andrew},
	urldate = {2024-01-02},
	date = {2015-04-10},
	eprinttype = {arxiv},
	eprint = {1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Conclusion, {TFM}},
}

@online{noauthor_papers_nodate,
	title = {Papers with Code - Vision Transformer Explained},
	url = {https://paperswithcode.com/method/vision-transformer},
	abstract = {The Vision Transformer, or {ViT}, is a model for image classification that employs a Transformer-like architecture over patches of the image.  An image is split into fixed-size patches, each of them are then linearly embedded, position embeddings are added, and the resulting sequence of vectors is fed to a standard Transformer encoder. In order to perform classification, the standard approach of adding an extra learnable “classification token” to the sequence is used.},
	urldate = {2024-01-02},
	langid = {english},
	keywords = {{TFM}, conclusion},
}

@online{belharar_enhancing_2023,
	title = {Enhancing Classification Accuracy for Imbalanced Image Data Using {SMOTE}},
	url = {https://medium.com/@fatimazahra.belharar/enhancing-classification-accuracy-for-imbalanced-image-data-using-smote-41737783a720},
	abstract = {In the world of data analysis and machine learning, not all datasets are created equal. One common challenge that often arises is dealing…},
	titleaddon = {Medium},
	author = {Belharar, Fatimazahra},
	urldate = {2023-12-27},
	date = {2023-06-07},
	langid = {english},
	keywords = {Building, {TFM}},
}

@online{maklin_synthetic_2022,
	title = {Synthetic Minority Over-sampling {TEchnique} ({SMOTE})},
	url = {https://medium.com/@corymaklin/synthetic-minority-over-sampling-technique-smote-7d419696b88c},
	abstract = {Synthetic Minority Over-sampling {TEchnique}, or {SMOTE} for short, is a preprocessing technique used to address a class imbalance in a…},
	titleaddon = {Medium},
	author = {Maklin, Cory},
	urldate = {2023-12-27},
	date = {2022-05-14},
	langid = {english},
	keywords = {{TFM} building},
}

@online{noauthor_smote_nodate,
	title = {{SMOTE} — Version 0.11.0},
	url = {https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#},
	urldate = {2023-12-27},
	keywords = {Building, {TFM}},
}

@misc{he_deep_2015,
	title = {Deep Residual Learning for Image Recognition},
	url = {http://arxiv.org/abs/1512.03385},
	doi = {10.48550/arXiv.1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the {ImageNet} dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than {VGG} nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the {ImageNet} test set. This result won the 1st place on the {ILSVRC} 2015 classification task. We also present analysis on {CIFAR}-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the {COCO} object detection dataset. Deep residual nets are foundations of our submissions to {ILSVRC} \& {COCO} 2015 competitions, where we also won the 1st places on the tasks of {ImageNet} detection, {ImageNet} localization, {COCO} detection, and {COCO} segmentation.},
	number = {{arXiv}:1512.03385},
	publisher = {{arXiv}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2023-12-26},
	date = {2015-12-10},
	eprinttype = {arxiv},
	eprint = {1512.03385 [cs]},
	keywords = {Building, Computer Science - Computer Vision and Pattern Recognition, {TFM}},
}

@misc{tan_efficientnet_2020,
	title = {{EfficientNet}: Rethinking Model Scaling for Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1905.11946},
	doi = {10.48550/arXiv.1905.11946},
	shorttitle = {{EfficientNet}},
	abstract = {Convolutional Neural Networks ({ConvNets}) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up {MobileNets} and {ResNet}. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called {EfficientNets}, which achieve much better accuracy and efficiency than previous {ConvNets}. In particular, our {EfficientNet}-B7 achieves state-of-the-art 84.3\% top-1 accuracy on {ImageNet}, while being 8.4x smaller and 6.1x faster on inference than the best existing {ConvNet}. Our {EfficientNets} also transfer well and achieve state-of-the-art accuracy on {CIFAR}-100 (91.7\%), Flowers (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
	number = {{arXiv}:1905.11946},
	publisher = {{arXiv}},
	author = {Tan, Mingxing},
	urldate = {2023-12-24},
	date = {2020-09-11},
	eprinttype = {arxiv},
	eprint = {1905.11946 [cs, stat]},
	note = {version: 5},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, {TFM}, building},
}

@misc{tan_efficientnet_2020-1,
	title = {{EfficientNet}: Rethinking Model Scaling for Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1905.11946},
	doi = {10.48550/arXiv.1905.11946},
	shorttitle = {{EfficientNet}},
	abstract = {Convolutional Neural Networks ({ConvNets}) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up {MobileNets} and {ResNet}. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called {EfficientNets}, which achieve much better accuracy and efficiency than previous {ConvNets}. In particular, our {EfficientNet}-B7 achieves state-of-the-art 84.3\% top-1 accuracy on {ImageNet}, while being 8.4x smaller and 6.1x faster on inference than the best existing {ConvNet}. Our {EfficientNets} also transfer well and achieve state-of-the-art accuracy on {CIFAR}-100 (91.7\%), Flowers (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
	number = {{arXiv}:1905.11946},
	publisher = {{arXiv}},
	author = {Tan, Mingxing and Le, Quoc V.},
	urldate = {2023-12-24},
	date = {2020-09-11},
	eprinttype = {arxiv},
	eprint = {1905.11946 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{shorten_survey_2019,
	title = {A survey on Image Data Augmentation for Deep Learning},
	volume = {6},
	doi = {10.1186/s40537-019-0197-0},
	number = {1},
	journaltitle = {{JOURNAL} {OF} {BIG} {DATA}},
	author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
	date = {2019-07-06},
	keywords = {State of Art, {TFM}, data augmentation},
}

@article{chen_review_2021,
	title = {Review of Image Classification Algorithms Based on Convolutional Neural Networks},
	volume = {13},
	doi = {10.3390/rs13224712},
	number = {22},
	journaltitle = {{REMOTE} {SENSING}},
	author = {Chen, Leiyu and Li, Shaobo and Bai, Qiang and Yang, Jing and Jiang, Sanlong and Miao, Yanming},
	date = {2021-11},
	keywords = {State of Art, {TFM}},
}

@article{shiri_comprehensive_nodate,
	title = {A Comprehensive Overview and Comparative Analysis on Deep Learning Models: {CNN}, {RNN}, {LSTM}, {GRU}},
	abstract = {Deep learning ({DL}) has emerged as a powerful subset of machine learning ({ML}) and artificial intelligence ({AI}), outperforming traditional {ML} methods, especially in handling unstructured and large datasets. Its impact spans across various domains, including speech recognition, healthcare, autonomous vehicles, cybersecurity, predictive analytics, and more. However, the complexity and dynamic nature of real-world problems present challenges in designing effective deep learning models. Consequently, several deep learning models have been developed to address different problems and applications. In this article, we conduct a comprehensive survey of various deep learning models, including Convolutional Neural Networks ({CNNs}), Recurrent Neural Networks ({RNNs}), Generative Models, Deep Reinforcement Learning ({DRL}), and Deep Transfer Learning. We examine the structure, applications, benefits, and limitations of each model. Furthermore, we perform an analysis using three publicly available datasets: {IMDB}, {ARAS}, and Fruit-360. We compare the performance of six renowned deep learning models: {CNN}, Simple {RNN}, Long Short-Term Memory ({LSTM}), Bidirectional {LSTM}, Gated Recurrent Unit ({GRU}), and Bidirectional {GRU}.},
	author = {Shiri, Farhad Mortezapour and Perumal, Thinagaran and Mustapha, Norwati and Mohamed, Raihani},
	langid = {english},
	keywords = {State of Art, {TFM}},
}

@online{wong_what_2021,
	title = {What is Residual Connection?},
	url = {https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55},
	abstract = {A technique for training very deep neural networks},
	titleaddon = {Medium},
	author = {Wong, Wanshun},
	urldate = {2023-10-23},
	date = {2021-12-18},
	langid = {english},
	keywords = {State of Art, {TFM}},
}

@misc{laina_deeper_2016,
	title = {Deeper Depth Prediction with Fully Convolutional Residual Networks},
	url = {http://arxiv.org/abs/1606.00373},
	abstract = {This paper addresses the problem of estimating the depth map of a scene given a single {RGB} image. We propose a fully convolutional architecture, encompassing residual learning, to model the ambiguous mapping between monocular images and depth maps. In order to improve the output resolution, we present a novel way to efficiently learn feature map up-sampling within the network. For optimization, we introduce the reverse Huber loss that is particularly suited for the task at hand and driven by the value distributions commonly present in depth maps. Our model is composed of a single architecture that is trained end-to-end and does not rely on post-processing techniques, such as {CRFs} or other additional refinement steps. As a result, it runs in real-time on images or videos. In the evaluation, we show that the proposed model contains fewer parameters and requires fewer training data than the current state of the art, while outperforming all approaches on depth estimation. Code and models are publicly available.},
	number = {{arXiv}:1606.00373},
	publisher = {{arXiv}},
	author = {Laina, Iro and Rupprecht, Christian and Belagiannis, Vasileios and Tombari, Federico and Navab, Nassir},
	urldate = {2023-10-23},
	date = {2016-09-19},
	eprinttype = {arxiv},
	eprint = {1606.00373 [cs]},
	note = {version: 2},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, State of Art, {TFM}},
}

@misc{roy_effects_2023,
	title = {Effects of Degradations on Deep Neural Network Architectures},
	url = {http://arxiv.org/abs/1807.10108},
	abstract = {Deep convolutional neural networks ({CNN}) have massively influenced recent advances in large-scale image classification. More recently, a dynamic routing algorithm with capsules (groups of neurons) has shown state-of-the-art recognition performance. However, the behavior of such networks in the presence of a degrading signal (noise) is mostly unexplored. An analytical study on different network architectures toward noise robustness is essential for selecting the appropriate model in a specific application scenario. This paper presents an extensive performance analysis of six deep architectures for image classification on six most common image degradation models. In this study, we have compared {VGG}-16, {VGG}-19, {ResNet}-50, Inception-v3, {MobileNet} and {CapsuleNet} architectures on Gaussian white, Gaussian color, salt-and-pepper, Gaussian blur, motion blur and {JPEG} compression noise models.},
	number = {{arXiv}:1807.10108},
	publisher = {{arXiv}},
	author = {Roy, Prasun and Ghosh, Subhankar and Bhattacharya, Saumik and Pal, Umapada},
	urldate = {2023-10-23},
	date = {2023-03-29},
	eprinttype = {arxiv},
	eprint = {1807.10108 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, State of Art, {TFM}},
}

@online{noauthor_what_nodate,
	title = {What is Deep Learning? {\textbar} {IBM}},
	url = {https://www.ibm.com/topics/deep-learning},
	shorttitle = {What is Deep Learning?},
	abstract = {Deep learning simulates our brain, helping systems learn to identify objects and perform complex tasks with increasing accuracy without human intervention.},
	urldate = {2023-10-23},
	langid = {english},
}

@article{talavera-martinez_hair_2021,
	title = {Hair Segmentation and Removal in Dermoscopic Images Using Deep Learning},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3047258},
	pages = {2694--2704},
	journaltitle = {{IEEE} {ACCESS}},
	author = {Talavera-Martinez, Lidia and Bibiloni, Pedro and Gonzalez-Hidalgo, Manuel},
	date = {2021},
	keywords = {State of Art, {TFM}, hair filter},
}

@article{bardou_hair_2022,
	title = {Hair removal in dermoscopy images using variational autoencoders},
	volume = {28},
	issn = {0909-752X},
	doi = {10.1111/srt.13145},
	pages = {445--454},
	number = {3},
	journaltitle = {{SKIN} {RESEARCH} {AND} {TECHNOLOGY}},
	author = {Bardou, Dalal and Bouaziz, Hamida and Lv, Laishui and Zhang, Ting},
	date = {2022-05},
	keywords = {State of Art, {TFM}, hair filter},
}

@article{kaur_hairlines_2022,
	title = {Hairlines removal and low contrast enhancement of melanoma skin images using convolutional neural network with aggregation of contextual information},
	volume = {76},
	issn = {1746-8094},
	doi = {10.1016/j.bspc.2022.103653},
	journaltitle = {{BIOMEDICAL} {SIGNAL} {PROCESSING} {AND} {CONTROL}},
	author = {Kaur, Ranpreet and {GholamHosseini}, Hamid and Sinha, Roopak},
	date = {2022-07},
	keywords = {State of Art, {TFM}, hair filter},
}

@article{rodrigues_new_2020,
	title = {A new approach for classification skin lesion based on transfer learning, deep learning, and {IoT} system},
	volume = {136},
	issn = {0167-8655},
	doi = {10.1016/j.patrec.2020.05.019},
	pages = {8--15},
	journaltitle = {{PATTERN} {RECOGNITION} {LETTERS}},
	author = {Rodrigues, Douglas de A. and Ivo, Roberto F. and Satapathy, Suresh Chandra and Wang, Shuihua and Hemanth, Jude and Reboucas Filho, Pedro P.},
	date = {2020-08},
	keywords = {State of Art, {TFM}, Transfer learning},
}

@inproceedings{wall_deep_2020,
	title = {Deep learning based melanoma diagnosis using dermoscopic images},
	volume = {12},
	isbn = {978-981-122-333-4},
	series = {World Scientific Proceedings Series on Computer Engineering and Information Science},
	pages = {907--914},
	booktitle = {{DEVELOPMENTS} {OF} {ARTIFICIAL} {IN}℡{LIGENCE} {TECHNOLOGIES} {IN} {COMPUTATION} {AND} {ROBOTICS}},
	publisher = {Fern Univ; {TH} Koln Univ Appl Sci; Univ Technol Sydney; {SW} Jiaotong Univ; Shunde Polytechn; Minnan Normal Univ; Natl Assoc Non Class Log \& Computat China},
	author = {Wall, Conor and Young, Fraser and Zhang, Li and Phillips, Emma-Jane and Jiang, Richard and Yu, Yonghong},
	editor = {Li, Z and Yuan, C and Lu, J and Kerre, {EE}},
	date = {2020},
	keywords = {State of Art, {TFM}, Transfer learning},
}

@inproceedings{abbes_deep_2021,
	title = {Deep Neural Networks for Melanoma Detection from Optical Standard Images using Transfer Learning},
	volume = {192},
	doi = {10.1016/j.procs.2021.08.134},
	series = {Procedia Computer Science},
	pages = {1304--1312},
	booktitle = {{KNOWLEDGE}-{BASED} {AND} {IN}℡{LIGENT} {INFORMATION} \& {ENGINEERING} {SYSTEMS} ({KSE} 2021)},
	publisher = {{KES} Int},
	author = {Abbes, Wiem and Sellami, Dorra},
	editor = {Watrobski, J and Salabun, W and Toro, C and Zanni-Merk, C and Howlett, {RJ} and Jain, {LC}},
	date = {2021},
	note = {{ISSN}: 1877-0509},
	keywords = {State of Art, {TFM}, Transfer learning},
}

@inproceedings{georgakopoulos_detection_2017,
	title = {Detection of Malignant Melanomas in Dermoscopic Images Using Convolutional Neural Network with Transfer Learning},
	volume = {744},
	isbn = {978-3-319-65172-9 978-3-319-65171-2},
	doi = {10.1007/978-3-319-65172-9_34},
	series = {Communications in Computer and Information Science},
	pages = {404--414},
	booktitle = {{ENGINEERING} {APPLICATIONS} {OF} {NEURAL} {NETWORKS}, {EANN} 2017},
	author = {Georgakopoulos, V, S. and Kottari, K. and Delibasis, K. and Plagianakos, V. P. and Maglogiannis, I},
	editor = {Boracchi, G and Iliadis, L and Jayne, C and Likas, A},
	date = {2017},
	note = {{ISSN}: 1865-0929},
	keywords = {State of Art, {TFM}, Transfer learning},
}

@article{celebi_automated_2014,
	title = {Automated Quantification of Clinically Significant Colors in Dermoscopy Images and Its Application to Skin Lesion Classification},
	volume = {8},
	issn = {1932-8184},
	doi = {10.1109/JSYST.2014.2313671},
	pages = {980--984},
	number = {3},
	journaltitle = {{IEEE} {SYSTEMS} {JOURNAL}},
	author = {Celebi, M. Emre and Zornberg, Azaria},
	date = {2014-09},
}

@article{abuzaghleh_noninvasive_2015,
	title = {Noninvasive Real-Time Automated Skin Lesion Analysis System for Melanoma Early Detection and Prevention},
	volume = {3},
	issn = {2168-2372},
	doi = {10.1109/JTEHM.2015.2419612},
	journaltitle = {{IEEE} {JOURNAL} {OF} {TRANSLATIONAL} {ENGINEERING} {IN} {HEALTH} {AND} {MEDICINE}},
	author = {Abuzaghleh, Omar and Barkana, Buket D. and Faezipour, Miad},
	date = {2015},
	keywords = {State of Art, {TFM}},
}

@article{thamizhamuthu_deep_2023,
	title = {Deep Learning-Based Dermoscopic Image Classification System for Robust Skin Lesion Analysis},
	volume = {40},
	issn = {0765-0019},
	doi = {10.18280/ts.400330},
	pages = {1145--1152},
	number = {3},
	journaltitle = {{TRAITEMENT} {DU} {SIGNAL}},
	author = {Thamizhamuthu, Rajamanickam and Maniraj, Subramanian Pitchiah},
	date = {2023-06},
	keywords = {State of Art, {TFM}},
}

@misc{le_building_2012,
	title = {Building high-level features using large scale unsupervised learning},
	url = {http://arxiv.org/abs/1112.6209},
	abstract = {We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous {SGD} on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting with these learned features, we trained our network to obtain 15.8\% accuracy in recognizing 20,000 object categories from {ImageNet}, a leap of 70\% relative improvement over the previous state-of-the-art.},
	number = {{arXiv}:1112.6209},
	publisher = {{arXiv}},
	author = {Le, Quoc V. and Ranzato, Marc'Aurelio and Monga, Rajat and Devin, Matthieu and Chen, Kai and Corrado, Greg S. and Dean, Jeff and Ng, Andrew Y.},
	urldate = {2023-10-22},
	date = {2012-07-12},
	eprinttype = {arxiv},
	eprint = {1112.6209 [cs]},
	keywords = {Computer Science - Machine Learning, State of Art, {TFM}},
}

@online{noauthor_what_nodate-1,
	title = {What is Deep Learning? {\textbar} {IBM}},
	url = {https://www.ibm.com/topics/deep-learning},
	shorttitle = {What is Deep Learning?},
	abstract = {Deep learning simulates our brain, helping systems learn to identify objects and perform complex tasks with increasing accuracy without human intervention.},
	urldate = {2023-10-21},
	langid = {english},
	keywords = {State of Art, {TFM}},
}

@online{noauthor_what_nodate-2,
	title = {What are Convolutional Neural Networks? {\textbar} {IBM}},
	url = {https://www.ibm.com/topics/convolutional-neural-networks},
	shorttitle = {What are Convolutional Neural Networks?},
	abstract = {Learn how convolutional neural networks use three-dimensional data to for image classification and object recognition tasks.},
	urldate = {2023-10-21},
	langid = {english},
	keywords = {State of Art, {TFM}},
}

@article{wells_medical_1998,
	title = {A medical expert system approach using artificial neural networks for standardized treatment planning},
	volume = {41},
	issn = {0360-3016},
	doi = {10.1016/S0360-3016(98)00035-2},
	pages = {173--182},
	number = {1},
	journaltitle = {{INTERNATIONAL} {JOURNAL} {OF} {RADIATION} {ONCOLOGY} {BIOLOGY} {PHYSICS}},
	author = {Wells, {DM} and Niederer, J},
	date = {1998-04-01},
	keywords = {State of Art, {TFM}},
}

@inproceedings{lee_machine_2009,
	title = {Machine Learning Framework for Classification in Medicine and Biology},
	volume = {5547},
	isbn = {978-3-642-01928-9},
	series = {Lecture Notes in Computer Science},
	pages = {1--7},
	booktitle = {{INTEGRATION} {OF} {AI} {AND} {OR} {TECHNIQUES} {IN} {CONSTRAINT} {PROGRAMMING} {FOR} {COMBINATORIAL} {OPTIMIZATION} {PROBLEMS}, {PROCEEDINGS}},
	author = {Lee, Kva K.},
	editor = {{VanHoeve}, {WJ} and Hooker, {JN}},
	date = {2009},
	note = {{ISSN}: 0302-9743},
	keywords = {State of Art, {TFM}},
}

@article{garnavi_computer-aided_2012,
	title = {Computer-Aided Diagnosis of Melanoma Using Border- and Wavelet-Based Texture Analysis},
	volume = {16},
	issn = {1089-7771},
	doi = {10.1109/TITB.2012.2212282},
	pages = {1239--1252},
	number = {6},
	journaltitle = {{IEEE} {TRANSACTIONS} {ON} {INFORMATION} {TECHNOLOGY} {IN} {BIOMEDICINE}},
	author = {Garnavi, Rahil and Aldeen, Mohammad and Bailey, James},
	date = {2012-11},
	keywords = {State of Art, {TFM}},
}

@article{dreiseitl_comparison_2001,
	title = {A comparison of machine learning methods for the diagnosis of pigmented skin lesions},
	volume = {34},
	issn = {1532-0464},
	doi = {10.1006/jbin.2001.1004},
	pages = {28--36},
	number = {1},
	journaltitle = {{JOURNAL} {OF} {BIOMEDICAL} {INFORMATICS}},
	author = {Dreiseitl, S and Ohno-Machado, L and Kittler, H and Vinterbo, S and Billhardt, H and Binder, M},
	date = {2001-02},
	keywords = {State of Art, {TFM}},
}

@inproceedings{dreiseitl_classifying_2000,
	title = {Classifying pigmented skin lesions with machine learning methods},
	isbn = {1-85233-289-1},
	series = {{PERSPECTIVES} {IN} {NEURAL} {COMPUTING}},
	pages = {174--179},
	booktitle = {{ARTIFICIAL} {NEURAL} {NETWORKS} {IN} {MEDICINE} {AND} {BIOLOGY}},
	publisher = {Artificial Neural Networks Med \& Biol; Fdn Knowledge \& Competence Dev},
	author = {Dreiseitl, S and Kittler, H and Ganster, H and Binder, M},
	editor = {Malmgren, H and Borga, M and Niklasson, L},
	date = {2000},
	note = {{ISSN}: 1431-6854},
	keywords = {State of Art, {TFM}},
}

@article{chan_expert_1996,
	title = {An expert system for the detection of cervical cancer cells using knowledge-based image analyzer},
	volume = {8},
	issn = {0933-3657},
	url = {https://www.sciencedirect.com/science/article/pii/0933365795000216},
	doi = {https://doi.org/10.1016/0933-3657(95)00021-6},
	abstract = {Analyzing for abnormalities of cell images in the cervix uteri provides a basis for reducing deaths and morbidity from cervical cancer through detection of potentially cancerous cells, provision of prompt advice and opportunities for follow-up and treatments. However, cytopathology is usually based on subjective interpretation of morphological features. Arbitrary criteria have to be devised for their classifications. Subjective interpretations of such criteria are likely to result in diagnostic shifts and consequently disagreement occurs between different interpreters. This article presents a novel approach to the composition of segmentation and diagnosis processes for biomedical image analysis. A prototype expert system has been developed to provide an objective and reliable tool to gynaecologists. Special image analyzing techniques are used and a set of knowledge sources is designed. The expert system employs a robust control strategy which minimizes the amount of domain-specific control knowledge. It has been proved to work effectively in the detection of cervical cancer.},
	pages = {67--90},
	number = {1},
	journaltitle = {Artificial Intelligence in Medicine},
	author = {Chan, Samuel W. K. and Leung, K. S. and Wong, W. S. Felix},
	date = {1996},
	keywords = {Cervical cancer, Expert system, Knowledge-based image analysis, Medical diagnosis, State of Art, {TFM}},
}

@article{celebi_automated_2014-1,
	title = {Automated Quantification of Clinically Significant Colors in Dermoscopy Images and Its Application to Skin Lesion Classification},
	volume = {8},
	issn = {1932-8184},
	doi = {10.1109/JSYST.2014.2313671},
	pages = {980--984},
	number = {3},
	journaltitle = {{IEEE} {SYSTEMS} {JOURNAL}},
	author = {Celebi, M. Emre and Zornberg, Azaria},
	date = {2014-09},
	keywords = {State of Art, {TFM}},
}

@article{beuscart_expert_1997,
	title = {An expert system for automatic analysis of whole body bone scintigraphy},
	volume = {21},
	issn = {0928-1258},
	pages = {56--62},
	number = {2},
	journaltitle = {{MEDECINE} {NUCLEAIRE}},
	author = {Beuscart, R and Wartski, M and Bourguignon, {MH} and Foucher, C},
	date = {1997},
	keywords = {State of Art, {TFM}},
}

@article{abbas_melanoma_2013,
	title = {Melanoma recognition framework based on expert definition of {ABCD} for dermoscopic images},
	volume = {19},
	issn = {0909-752X},
	doi = {10.1111/j.1600-0846.2012.00614.x},
	pages = {E93--E102},
	number = {1},
	journaltitle = {{SKIN} {RESEARCH} {AND} {TECHNOLOGY}},
	author = {Abbas, Qaisar and Celebi, M. Emre and Fondon Garcia, Irene and Ahmad, Waqar},
	date = {2013-02},
	keywords = {State of Art, {TFM}},
}

@article{castellani_dce-mri_2009,
	title = {{DCE}-{MRI} Data Analysis for Cancer Area Classification},
	volume = {48},
	issn = {0026-1270},
	doi = {10.3414/ME9224},
	pages = {248--253},
	number = {3},
	journaltitle = {{METHODS} {OF} {INFORMATION} {IN} {MEDICINE}},
	author = {Castellani, U. and Cristani, M. and Daducci, A. and Farace, P. and Marzola, P. and Murino, V. and Sbarbati, A.},
	date = {2009},
}

@inproceedings{okada_stratified_2008,
	title = {Stratified Regularity Measures with Jensen-Shannon Divergence},
	isbn = {978-1-4244-2339-2},
	series = {{IEEE} Conference on Computer Vision and Pattern Recognition},
	pages = {526+},
	booktitle = {2008 {IEEE} {COMPUTER} {SOCIETY} {CONFERENCE} {ON} {COMPUTER} {VISION} {AND} {PATTERN} {RECOGNITION} {WORKSHOPS}, {VOLS} 1-3},
	publisher = {{IEEE} Comp Soc},
	author = {Okada, Kazunori and Periaswamy, Senthil and Bi, Jinbo},
	date = {2008},
	note = {{ISSN}: 1063-6919},
}

@article{chan_characterization_2010,
	title = {Characterization of masses in digital breast tomosynthesis: Comparison of machine learning in projection views and reconstructed slices},
	volume = {37},
	issn = {0094-2405},
	doi = {10.1118/1.3432570},
	pages = {3576--3586},
	number = {7},
	journaltitle = {{MEDICAL} {PHYSICS}},
	author = {Chan, Heang-Ping and Wu, Yi-Ta and Sahiner, Berkman and Wei, Jun and Helvie, Mark A. and Zhang, Yiheng and Moore, Richard H. and Kopans, Daniel B. and Hadjiiski, Lubomir and Way, Ted},
	date = {2010-07},
}

@article{depeursinge_comparative_2010,
	title = {Comparative Performance Analysis of State-of-the-Art Classification Algorithms Applied to Lung Tissue Categorization},
	volume = {23},
	issn = {0897-1889},
	doi = {10.1007/s10278-008-9158-4},
	pages = {18--30},
	number = {1},
	journaltitle = {{JOURNAL} {OF} {DIGITAL} {IMAGING}},
	author = {Depeursinge, Adrien and Iavindrasana, Jimison and Hidki, Asmaa and Cohen, Gilles and Geissbuhler, Antoine and Platon, Alexandra and Poletti, Pierre-Alexandre and Mueller, Henning},
	date = {2010-02},
}

@article{diaz_semi-automatic_2009,
	title = {A semi-automatic method for quantification and classification of erythrocytes infected with malaria parasites in microscopic images},
	volume = {42},
	issn = {1532-0464},
	doi = {10.1016/j.jbi.2008.11.005},
	pages = {296--307},
	number = {2},
	journaltitle = {{JOURNAL} {OF} {BIOMEDICAL} {INFORMATICS}},
	author = {Diaz, Gloria and Gonzalez, Fabio A. and Romero, Eduardo},
	date = {2009-04},
}

@article{chapotot_automated_2010,
	title = {Automated sleep-wake staging combining robust feature extraction, artificial neural network classification, and flexible decision rules},
	volume = {24},
	issn = {0890-6327},
	doi = {10.1002/acs.1147},
	pages = {409--423},
	number = {5},
	journaltitle = {{INTERNATIONAL} {JOURNAL} {OF} {ADAPTIVE} {CONTROL} {AND} {SIGNAL} {PROCESSING}},
	author = {Chapotot, Florian and Becq, Guillaume},
	date = {2010-05},
}

@article{fan_compare_2007,
	title = {{COMPARE}: Classification of morphological patterns using adaptive regional elements},
	volume = {26},
	issn = {0278-0062},
	doi = {10.1109/TMI.2006.886812},
	pages = {93--105},
	number = {1},
	journaltitle = {{IEEE} {TRANSACTIONS} {ON} {MEDICAL} {IMAGING}},
	author = {Fan, Yong and Shen, Dinggang and Gur, Ruben C. and Gur, Raquel E. and Davatzikos, Christos},
	date = {2007-01},
}

@article{gilmore_support_2010,
	title = {A support vector machine for decision support in melanoma recognition},
	volume = {19},
	issn = {0906-6705},
	doi = {10.1111/j.1600-0625.2010.01112.x},
	pages = {830--835},
	number = {9},
	journaltitle = {{EXPERIMENTAL} {DERMATOLOGY}},
	author = {Gilmore, Stephen and Hofmann-Wellenhof, Rainer and Soyer, H. Peter},
	date = {2010-09},
}

@inproceedings{liao_novel_2007,
	title = {A novel affine invariant feature extraction for optical recognition},
	isbn = {978-1-4244-0972-3},
	pages = {1769+},
	booktitle = {{PROCEEDINGS} {OF} 2007 {INTERNATIONAL} {CONFERENCE} {ON} {MACHINE} {LEARNING} {AND} {CYBERNETICS}, {VOLS} 1-7},
	publisher = {Machine Learning \& Cybernet Res Inst; Hebei Univ; {IEEE} Syst, Man \& Cybernet Soc; Harbin Inst Technol Shenzhen Grad Sch; Chinese Univ Hong Kong; City Univ Hong Kong; Hong Kong Baptist Univ; Hong Kong Univ, Sci \& Technol; Int Fuzzy Syst Assoc; Hebei Univ Sci \& Technol},
	author = {Liao, Melody Z. W. and Wei, Ling and Chen, W. F.},
	date = {2007},
}

@inproceedings{koompairojn_computer-aided_2010,
	title = {Computer-Aided Diagnosis of Lumbar Stenosis Conditions},
	volume = {7624},
	isbn = {978-0-8194-8025-5},
	doi = {10.1117/12.844545},
	series = {Proceedings of {SPIE}},
	booktitle = {{MEDICAL} {IMAGING} 2010: {COMPUTER} - {AIDED} {DIAGNOSIS}},
	publisher = {{SPIE}; Medtronic Inc; Aeroflex Inc; Tungsten Heavy Powder, Inc},
	author = {Koompairojn, Soontharee and Hua, Kathleen and Hua, Kien A. and Srisomboon, Jintavaree},
	editor = {Karssemeijer, N and Summers, {RM}},
	date = {2010},
	note = {{ISSN}: 0277-786X},
}

@article{li_automatic_2006,
	title = {Automatic clinical image segmentation using pathological modeling, {PCA} and {SVM}},
	volume = {19},
	issn = {0952-1976},
	doi = {10.1016/j.engappai.2006.01.011},
	pages = {403--410},
	number = {4},
	journaltitle = {{ENGINEERING} {APPLICATIONS} {OF} {ARTIFICIAL} {IN}℡{LIGENCE}},
	author = {Li, Shuo and Fevens, Thomas and Krzyzak, Adam and Li, Song},
	date = {2006-06},
}

@inproceedings{lalys_automatic_2010,
	title = {Automatic Phases Recognition in Pituitary Surgeries by Microscope Images Classification},
	volume = {6135},
	isbn = {978-3-642-13710-5},
	series = {Lecture Notes in Computer Science},
	pages = {34+},
	booktitle = {{INFORMATION} {PROCESSING} {IN} {COMPUTER}-{ASSISTED} {INTERVENTIONS}},
	author = {Lalys, Florent and Riffaud, Laurent and Morandi, Xavier and Jannin, Pierre},
	editor = {Navab, N and Jannin, P},
	date = {2010},
	note = {{ISSN}: 0302-9743},
}

@article{moayedi_contourlet-based_2010,
	title = {Contourlet-based mammography mass classification using the {SVM} family},
	volume = {40},
	issn = {0010-4825},
	doi = {10.1016/j.compbiomed.2009.12.006},
	pages = {373--383},
	number = {4},
	journaltitle = {{COMPUTERS} {IN} {BIOLOGY} {AND} {MEDICINE}},
	author = {Moayedi, Fatemeh and Azimifar, Zohreh and Boostani, Reza and Katebi, Serajodin},
	date = {2010-04},
}

@article{tuzel_classification_2007,
	title = {Classification of hematologic malignancies using texton signatures},
	volume = {10},
	issn = {1433-7541},
	doi = {10.1007/s10044-007-0066-x},
	pages = {277--290},
	number = {4},
	journaltitle = {{PATTERN} {ANALYSIS} {AND} {APPLICATIONS}},
	author = {Tuzel, Oncel and Yang, Lin and Meer, Peter and Foran, David J.},
	date = {2007-10},
}

@article{voigt_classification_2010,
	title = {Classification of functional voice disorders based on phonovibrograms},
	volume = {49},
	issn = {0933-3657},
	doi = {10.1016/j.artmed.2010.01.001},
	pages = {51--59},
	number = {1},
	journaltitle = {{ARTIFICIAL} {IN}℡{LIGENCE} {IN} {MEDICINE}},
	author = {Voigt, Daniel and Doellinger, Michael and Braunschweig, Thomas and Yang, Anxiong and Eysholdt, Ulrich and Lohscheller, Joerg},
	date = {2010-05},
}

@article{scully_automated_2010,
	title = {An automated method for segmenting white matter lesions through multi-level morphometric feature classification with application to lupus},
	volume = {4},
	issn = {1662-5161},
	doi = {10.3389/fnhum.2010.00027},
	journaltitle = {{FRONTIERS} {IN} {HUMAN} {NEUROSCIENCE}},
	author = {Scully, Mark and Anderson, Blake and Lane, Terran and Gasparovic, Charles and Magnotta, Vince and Sibbitt, Wilmer and Roldan, Carlos and Kikinis, Ron and Bockholt, Henry J.},
	date = {2010-04},
}

@article{zacharaki_classification_2009,
	title = {Classification of Brain Tumor Type and Grade Using {MRI} Texture and Shape in a Machine Learning Scheme},
	volume = {62},
	issn = {0740-3194},
	doi = {10.1002/mrm.22147},
	pages = {1609--1618},
	number = {6},
	journaltitle = {{MAGNETIC} {RESONANCE} {IN} {MEDICINE}},
	author = {Zacharaki, Evangelia I. and Wang, Sumei and Chawla, Sanjeev and Yoo, Dong Soo and Wolf, Ronald and Melhem, Elias R. and Davatzikos, Christos},
	date = {2009-12},
}

@inproceedings{thies_classification_2006,
	title = {A classification framework for content-based extraction of biomedical objects from hierarchically decomposed images},
	volume = {6144},
	isbn = {0-8194-6423-6},
	doi = {10.1117/12.653503},
	series = {Proceedings of {SPIE}},
	booktitle = {{MEDICAL} {IMAGING} 2006: {IMAGE} {PROCESSING}, {PTS} 1-3},
	publisher = {{SPIE}},
	author = {Thies, Christian and Borreda, Marcel Schmidt and Seidl, Thomas and Lehmann, Thomas M.},
	editor = {Reinhardt, {JM} and Pluim, {JPW}},
	date = {2006},
	note = {{ISSN}: 0277-786X
Issue: 1-3},
}

@inproceedings{depeursinge_classification_2008,
	title = {A classification framework for lung tissue categorization},
	volume = {6919},
	isbn = {978-0-8194-7103-1},
	doi = {10.1117/12.769190},
	series = {Proceedings of {SPIE}},
	booktitle = {{MEDICAL} {IMAGING} 2008: {PACS} {AND} {IMAGING} {INFORMATICS}},
	publisher = {{SPIE}; Amer Assoc Phys Med; Amer Physiol Soc; Comp Assisted Radiol \& Surg; Soc Imaging Sci \& Technol; Med Image Percept Soc; Radiol Soc N Amer; Soc Imaging Informat Med; Soc Mol Imaging; {DICOM} Standards Comm},
	author = {Depeursinge, Adrien and Lavindrasana, Jimison and Hidki, Asmaa and Cohen, Gilles and Geissbuhler, Antoine and Platon, Alexandra and Poletti, Pierre-Alexandre and Mueller, Henning},
	editor = {Andriole, {KP} and Siddiqui, {KM}},
	date = {2008},
	note = {{ISSN}: 0277-786X},
}

@inproceedings{daducci_learning_2009,
	title = {Learning Approach to Analyze Tumour Heterogeneity in {DCE}-{MRI} Data During Anti-cancer Treatment},
	volume = {5651},
	isbn = {978-3-642-02975-2},
	series = {Lecture Notes in Artificial Intelligence},
	pages = {385+},
	booktitle = {{ARTIFICIAL} {IN}℡{LIGENCE} {IN} {MEDICINE}, {PROCEEDINGS}},
	publisher = {European Soc Artificial Intelligence Med},
	author = {Daducci, Alessandro and Castellani, Umberto and Cristani, Marco and Farace, Paolo and Marzola, Pasquina and Sbarbati, Andrea and Murino, Vittorio},
	editor = {Combi, C and Shahar, Y and {AbuHanna}, A},
	date = {2009},
	note = {{ISSN}: 0302-9743},
}

@inproceedings{ramos_pollan_grid_2010,
	title = {Grid Computing for Breast Cancer {CAD}. A Pilot Experience in a Medical Environment},
	isbn = {978-84-9745-549-7},
	pages = {307+},
	booktitle = {{IBERGRID}: 4TH {IBERIAN} {GRID} {INFRASTRUCTURE} {CONFERENCE} {PROCEEDINGS}},
	publisher = {Portuguese Ministry Sci Tech Higher Educ; Spanish Ministry Educ Sci; Bull; {IBM}; {HP}; Oracle; Microsoft},
	author = {Ramos Pollan, Raul and Miguel Franco, Jose and Sevilla, Jorge and de Posada, Naimy Gonzalez and Perez, Noel Perez and Pires Vaz, Mario Augusto and Loureiro, Joana and Ramos, Isabel and Guevara Lopez, Miguel Angel},
	editor = {Proenca, A and Pina, A and Tobio, {JG} and Ribeiro, L},
	date = {2010},
}

@inproceedings{yang_learning_2007,
	title = {Learning distance metrics for interactive search-assisted diagnosis of mammograms},
	volume = {6514},
	isbn = {978-0-8194-6632-7},
	doi = {10.1117/12.710076},
	series = {Proceedings of {SPIE}},
	booktitle = {{MEDICAL} {IMAGING} 2007: {COMPUTER}-{AIDED} {DIAGNOSIS}, {PTS} 1 {AND} 2},
	publisher = {{SPIE}; Amer Assoc Physicists; Amer Physiol Soc; Comp Assisted Radiol \& Surg; Soc Imaging Sci \& Technol; Med Image Percept Soc; Radiol Soc N Amer; Soc Imaging Informat Med; Soc Mol Imaging; {DICOM} Standards Comm},
	author = {Yang, Liu and Jin, Rong and Sukthankar, Rahul and Zheng, Bin and Mummert, Lily and Satyanarayanan, M. and Chen, Mei and Jukic, Drazen},
	editor = {Giger, {ML} and Karssemeijer, N},
	date = {2007},
	note = {{ISSN}: 0277-786X
Issue: 1-2},
}

@inproceedings{guan_minimizing_2010,
	title = {Minimizing the Semantic Gap in Biomedical Content-Based Image Retrieval},
	volume = {7628},
	isbn = {978-0-8194-8029-3},
	doi = {10.1117/12.844470},
	series = {Proceedings of {SPIE}},
	booktitle = {{MEDICAL} {IMAGING} 2010: {ADVANCED} {PACS}-{BASED} {IMAGING} {INFORMATICS} {AND} {THERAPEUTIC} {APPLICATIONS}},
	publisher = {{SPIE}; Medtronic Inc; Aeroflex Inc; Tungsten Heavy Powder Inc},
	author = {Guan, Haiying and Antani, Sameer and Long, L. Rodney and Thoma, George R.},
	editor = {Liu, {BJ} and Boonn, {WW}},
	date = {2010},
	note = {{ISSN}: 0277-786X},
}

@article{savio_neural_2010,
	title = {{NEURAL} {CLASSIFIERS} {FOR} {SCHIZOPHRENIA} {DIAGNOSTIC} {SUPPORT} {ON} {DIFFUSION} {IMAGING} {DATA}},
	volume = {20},
	issn = {1210-0552},
	pages = {935--949},
	number = {7},
	journaltitle = {{NEURAL} {NETWORK} {WORLD}},
	author = {Savio, Alexandre and Charpentier, Juliette and Termenon, Maite and Shinn, Ann K. and Grana, Manuel},
	date = {2010},
}

@article{ruan_online_2010,
	title = {Online prediction of respiratory motion: multidimensional processing with low-dimensional feature learning},
	volume = {55},
	issn = {0031-9155},
	doi = {10.1088/0031-9155/55/11/002},
	pages = {3011--3025},
	number = {11},
	journaltitle = {{PHYSICS} {IN} {MEDICINE} {AND} {BIOLOGY}},
	author = {Ruan, Dan and Keall, Paul},
	date = {2010-06-07},
}

@article{yuan_roundness_2010,
	title = {{ROUNDNESS} {CURVE} {OF} {SHAPE} {AND} {APPLICATION}},
	volume = {6},
	issn = {1349-4198},
	pages = {1915--1923},
	number = {4},
	journaltitle = {{INTERNATIONAL} {JOURNAL} {OF} {INNOVATIVE} {COMPUTING} {INFORMATION} {AND} {CONTROL}},
	author = {Yuan, Kehong and Duan, Caijie and Han, Wei and Chen, Chao},
	date = {2010-04},
}

@article{labusch_simple_2008,
	title = {Simple Method for High-Performance Digit Recognition Based on Sparse Coding},
	volume = {19},
	issn = {1045-9227},
	doi = {10.1109/TNN.2008.2005830},
	pages = {1985--1989},
	number = {11},
	journaltitle = {{IEEE} {TRANSACTIONS} {ON} {NEURAL} {NETWORKS}},
	author = {Labusch, Kai and Barth, Erhardt and Martinetz, Thomas},
	date = {2008-11},
}

@article{fang_automated_2008,
	title = {Automated diagnosis of fetal alcohol syndrome using 3D facial image analysis},
	volume = {11},
	issn = {1601-6335},
	doi = {10.1111/j.1601-6343.2008.00425.x},
	pages = {162--171},
	number = {3},
	journaltitle = {{ORTHODONTICS} \& {CRANIOFACIAL} {RESEARCH}},
	author = {Fang, S. and {McLaughlin}, J. and Fang, J. and Huang, J. and Autti-Ramo, I. and Fagerlund, A. and Jacobson, S. W. and Robinson, L. K. and Hoyme, H. E. and Mattson, S. N. and Riley, E. and Zhou, F. and Ward, R. and Moore, E. S. and Foroud, T. and Alc, Collaborative Initiative Fetal},
	date = {2008-08},
}

@inproceedings{you_biomedical_2010,
	title = {Biomedical Article Retrieval Using Multimodal Features and Image Annotations in Region-based {CBIR}},
	volume = {7534},
	isbn = {978-0-8194-7927-3},
	doi = {10.1117/12.838973},
	series = {Proceedings of {SPIE}},
	booktitle = {{DOCUMENT} {RECOGNITION} {AND} {RETRIEVAL} {XVII}},
	publisher = {{SPIE}; {IS} \& T (Soc Imaging Sci \& Technol); Inst Telecom},
	author = {You, Daekeun and Antani, Sameer and Demner-Fushman, Dina and Rahman, Md Mahmudur and Govindaraju, Venu and Thoma, George R.},
	editor = {Likforman-Sulem, L and Agam, G},
	date = {2010},
	note = {{ISSN}: 0277-786X},
}

@article{gilfeather_learning_2007,
	title = {Learning and modeling biosignatures from tissue images},
	volume = {37},
	issn = {0010-4825},
	doi = {10.1016/j.compbiomed.2007.02.005},
	pages = {1539--1552},
	number = {11},
	journaltitle = {{COMPUTERS} {IN} {BIOLOGY} {AND} {MEDICINE}},
	author = {Gilfeather, Frank and Hamine, Vikas and Helman, Paul and Hutt, Julie and Loring, Terry and Lyons, C. Rick and Veroff, Robert},
	date = {2007-11},
}

@inproceedings{lee_machine_2009-1,
	title = {Machine Learning Framework for Classification in Medicine and Biology},
	volume = {5547},
	isbn = {978-3-642-01928-9},
	series = {Lecture Notes in Computer Science},
	pages = {1--7},
	booktitle = {{INTEGRATION} {OF} {AI} {AND} {OR} {TECHNIQUES} {IN} {CONSTRAINT} {PROGRAMMING} {FOR} {COMBINATORIAL} {OPTIMIZATION} {PROBLEMS}, {PROCEEDINGS}},
	author = {Lee, Kva K.},
	editor = {{VanHoeve}, {WJ} and Hooker, {JN}},
	date = {2009},
	note = {{ISSN}: 0302-9743},
}

@online{noauthor_cc_nodate,
	title = {{CC} {BY}-{NC} 4.0 Deed {\textbar} Attribution-{NonCommercial} 4.0 International {\textbar} Creative Commons},
	url = {https://creativecommons.org/licenses/by-nc/4.0/},
	urldate = {2023-10-10},
}

@online{luciaclemares_que_2023,
	title = {¿Qué beneficios tiene la Inteligencia Artificial en la medicina?},
	url = {https://www.telefonica.com/es/sala-comunicacion/blog/que-beneficios-tiene-la-inteligencia-artificial-en-la-medicina/},
	abstract = {El uso de la Inteligencia Artificial en la medicina permite crear modelos de aprendizaje automático para personalizar los tratamientos de los pacientes},
	titleaddon = {Telefónica},
	author = {luciaclemares},
	urldate = {2023-10-09},
	date = {2023-03-10},
	langid = {spanish},
	keywords = {Motivation},
}

@online{noauthor_aplicaciones_2021,
	title = {Aplicaciones reales de la inteligencia artificial en la medicina},
	url = {https://www.apd.es/aplicaciones-inteligencia-artificial-en-medicina/},
	abstract = {¿Conoces los efectos de la inteligencia artificial en la medicina? Descubre todos los beneficios que puede aportar y sus aplicaciones más novedosas},
	titleaddon = {{APD} España},
	urldate = {2023-10-09},
	date = {2021-02-23},
	langid = {spanish},
	keywords = {Motivation},
}

@inreference{noauthor_cross_2023,
	title = {Cross Industry Standard Process for Data Mining},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://es.wikipedia.org/w/index.php?title=Cross_Industry_Standard_Process_for_Data_Mining&oldid=154176991},
	abstract = {{CRISP}-{DM}  (del inglés Cross Industry Standard Process for Data Mining)[1]​ se trata de un modelo estándar abierto del proceso que describe los enfoques comunes que utilizan los expertos en minería de datos. Es el modelo analítico más usado.[2]​},
	booktitle = {Wikipedia, la enciclopedia libre},
	urldate = {2023-10-08},
	date = {2023-09-29},
	langid = {spanish},
	note = {Page Version {ID}: 154176991},
}

@online{noauthor_isic_nodate,
	title = {{ISIC} {\textbar} International Skin Imaging Collaboration},
	url = {https://www.isic-archive.com},
	abstract = {{ISIC} is improving skin cancer diagnosis by promoting standards in skin imaging, gathering and sharing dermatologic images, \& engaging clinicians \& computer vision researchers},
	titleaddon = {{ISIC}},
	urldate = {2023-10-08},
	langid = {english},
	keywords = {{ISIC}},
}

@online{noauthor_zotero_nodate,
	title = {Zotero {\textbar} Your personal research assistant},
	url = {https://www.zotero.org/},
	urldate = {2023-10-08},
}

@online{noauthor_today_nodate,
	title = {Today 2 h 39 min - {TMetric}},
	url = {https://app.tmetric.com/#/tracker/31766/},
	urldate = {2023-10-07},
}

@online{noauthor_transferir_nodate,
	title = {Transferir el aprendizaje y la puesta a punto {\textbar} {TensorFlow} Core},
	url = {https://www.tensorflow.org/guide/keras/transfer_learning?hl=es-419},
	titleaddon = {{TensorFlow}},
	urldate = {2022-06-08},
	langid = {spanish},
}

@online{noauthor_guiavanzada_nodate,
	title = {Guía avanzada de Inception v3 {\textbar} Cloud {TPU}},
	url = {https://cloud.google.com/tpu/docs/inception-v3-advanced?hl=es-419},
	titleaddon = {Google Cloud},
	urldate = {2022-06-08},
	langid = {spanish},
}

@inreference{noauthor_imagenet_2022,
	title = {{ImageNet}},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=ImageNet&oldid=1087083779},
	abstract = {The {ImageNet} project is a large visual database designed for use in visual object recognition software research. More than 14 million images have been hand-annotated by the project to indicate what objects are pictured and in at least one million of the images, bounding boxes are also provided. {ImageNet} contains more than 20,000 categories, with a typical category, such as "balloon" or "strawberry", consisting of several hundred images. The database of annotations of third-party image {URLs} is freely available directly from {ImageNet}, though the actual images are not owned by {ImageNet}. Since 2010, the {ImageNet} project runs an annual software contest, the {ImageNet} Large Scale Visual Recognition Challenge ({ILSVRC}), where software programs compete to correctly classify and detect objects and scenes. The challenge uses a "trimmed" list of one thousand non-overlapping classes.},
	booktitle = {Wikipedia},
	urldate = {2022-06-08},
	date = {2022-05-10},
	langid = {english},
	note = {Page Version {ID}: 1087083779},
}

@online{team_keras_nodate,
	title = {Keras documentation: Keras Applications},
	url = {https://keras.io/api/applications/#usage-examples-for-image-classification-models%22},
	shorttitle = {Keras documentation},
	abstract = {Keras documentation},
	author = {Team, Keras},
	urldate = {2022-06-08},
	langid = {english},
}

@report{tan_efficientnet_2020-2,
	title = {{EfficientNet}: Rethinking Model Scaling for Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1905.11946},
	shorttitle = {{EfficientNet}},
	abstract = {Convolutional Neural Networks ({ConvNets}) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up {MobileNets} and {ResNet}. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called {EfficientNets}, which achieve much better accuracy and efficiency than previous {ConvNets}. In particular, our {EfficientNet}-B7 achieves state-of-the-art 84.3\% top-1 accuracy on {ImageNet}, while being 8.4x smaller and 6.1x faster on inference than the best existing {ConvNet}. Our {EfficientNets} also transfer well and achieve state-of-the-art accuracy on {CIFAR}-100 (91.7\%), Flowers (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
	number = {{arXiv}:1905.11946},
	institution = {{arXiv}},
	author = {Tan, Mingxing and Le, Quoc V.},
	urldate = {2022-06-08},
	date = {2020-09-11},
	doi = {10.48550/arXiv.1905.11946},
	eprinttype = {arxiv},
	eprint = {1905.11946 [cs, stat]},
	note = {type: article},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@online{team_keras_nodate-1,
	title = {Keras documentation: {EfficientNet} B0 to B7},
	url = {https://keras.io/api/applications/efficientnet/},
	shorttitle = {Keras documentation},
	abstract = {Keras documentation},
	author = {Team, Keras},
	urldate = {2022-06-08},
	langid = {english},
}

@online{noauthor_practica_nodate,
	title = {Practica {DL} {UOC} 2022},
	url = {https://www.kaggle.com/jordidelatorreuoc/practica-dl-uoc-2022},
	abstract = {Kaggle is the world’s largest data science community with powerful tools and resources to help you achieve your data science goals.},
	urldate = {2022-06-08},
	langid = {english},
}

@article{diaz-pinto_cnns_2019,
	title = {{CNNs} for automatic glaucoma assessment using fundus images: an extensive validation},
	volume = {18},
	issn = {1475-925X},
	url = {https://doi.org/10.1186/s12938-019-0649-y},
	doi = {10.1186/s12938-019-0649-y},
	shorttitle = {{CNNs} for automatic glaucoma assessment using fundus images},
	abstract = {Most current algorithms for automatic glaucoma assessment using fundus images rely on handcrafted features based on segmentation, which are affected by the performance of the chosen segmentation method and the extracted features. Among other characteristics, convolutional neural networks ({CNNs}) are known because of their ability to learn highly discriminative features from raw pixel intensities.},
	pages = {29},
	number = {1},
	journaltitle = {{BioMedical} Engineering {OnLine}},
	shortjournal = {{BioMedical} Engineering {OnLine}},
	author = {Diaz-Pinto, Andres and Morales, Sandra and Naranjo, Valery and Köhler, Thomas and Mossi, Jose M. and Navea, Amparo},
	urldate = {2022-06-08},
	date = {2019-03-20},
	keywords = {{ACRIMA} database, {CNN}, Fine-tuning, Fundus images, Glaucoma},
}
