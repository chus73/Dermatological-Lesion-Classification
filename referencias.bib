%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Jordi Casas Roma at 2018-05-29 18:21:49 +0200 

%% Saved with string encoding Unicode (UTF-8) 


%% License
@misc{cc_by_nc_license,
    key = {cc_by_nc license}, 
	title = {{CC} {BY}-{NC} 4.0 Deed Attribution-{NonCommercial} 4.0 International Creative Commons},
    note = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55}, \url{https://creativecommons.org/licenses/by-nc/4.0/}},
	urldate = {2023-10-10},
}

%% Acknowledgements
@misc{isic_web,
    key = {International Skin Imaging Collaboration},
	title = {{ISIC} {\textbar} International Skin Imaging Collaboration},
    note = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55}, \url{https://www.isic-archive.com}},
	abstract = {{ISIC} is improving skin cancer diagnosis by promoting standards in skin imaging, gathering and sharing dermatologic images, \& engaging clinicians \& computer vision researchers},
	titleaddon = {{ISIC}},
	urldate = {2023-10-08},
	langid = {english},
	keywords = {{ISIC}},
}

%% Introduction

@misc{luciaclemares_que_2023,
	title = {¿Qué beneficios tiene la Inteligencia Artificial en la medicina?},
    note = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55},  \url{https://www.telefonica.com/es/sala-comunicacion/blog/que-beneficios-tiene-la-inteligencia-artificial-en-la-medicina/}},
	abstract = {El uso de la Inteligencia Artificial en la medicina permite crear modelos de aprendizaje automático para personalizar los tratamientos de los pacientes},
	titleaddon = {Telefónica},
	author = {luciaclemares},
	urldate = {2023-10-09},
	date = {2023-03-10},
	langid = {spanish},
	keywords = {Motivation},
}

%% State of the ART

@misc{apd_aplicaciones_IA_Medicina,
    key = {aplicaciones reales IA en medicina},
	title = {Aplicaciones reales de la inteligencia artificial en la medicina},
	note = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55}, 
	\url{https://www.apd.es/aplicaciones-inteligencia-artificial-en-medicina/}},
	abstract = {¿Conoces los efectos de la inteligencia artificial en la medicina? Descubre todos los beneficios que puede aportar y sus aplicaciones más novedosas},
	titleaddon = {{APD} España},
	urldate = {2023-10-09},
	date = {2021-02-23},
	langid = {spanish},
	keywords = {Motivation},
}

@ARTICLE{6263297,
  author={Garnavi, Rahil and Aldeen, Mohammad and Bailey, James},
  journal={IEEE Transactions on Information Technology in Biomedicine}, 
  title={Computer-Aided Diagnosis of Melanoma Using Border- and Wavelet-Based Texture Analysis}, 
  year={2012},
  volume={16},
  number={6},
  pages={1239-1252},
  abstract={This paper presents a novel computer-aided diagnosis system for melanoma. The novelty lies in the optimized selection and integration of features derived from textural, border-based, and geometrical properties of the melanoma lesion. The texture features are derived from using wavelet-decomposition, the border features are derived from constructing a boundary-series model of the lesion border and analyzing it in spatial and frequency domains, and the geometry features are derived from shape indexes. The optimized selection of features is achieved by using the gain-ratio method, which is shown to be computationally efficient for melanoma diagnosis application. Classification is done through the use of four classifiers; namely, support vector machine, random forest, logistic model tree, and hidden naive Bayes. The proposed diagnostic system is applied on a set of 289 dermoscopy images (114 malignant, 175 benign) partitioned into train, validation, and test image sets. The system achieves an accuracy of 91.26% and area under curve value of 0.937, when 23 features are used. Other important findings include 1) the clear advantage gained in complementing texture with border and geometry features, compared to using texture information only, and 2) higher contribution of texture features than border-based features in the optimized feature set.},
  keywords={},
  DOI={10.1109/TITB.2012.2212282},
  ISSN={1558-0032},
  month={Nov},
  note = { 
        {DOI: 10.1109/TITB.2012.2212282}, 
        {ISSN: 1558-0032}},
}

@ARTICLE{6803866,
  author={Celebi, M. Emre and Zornberg, Azaria},
  journal={IEEE Systems Journal}, 
  title={Automated Quantification of Clinically Significant Colors in Dermoscopy Images and Its Application to Skin Lesion Classification}, 
  year={2014},
  volume={8},
  number={3},
  pages={980-984},
  DOI={10.1109/JSYST.2014.2313671}}


@misc{noauthor_what_nodate,
	title = {What is Deep Learning? {\textbar} {IBM}},
    note = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55}, \url{https://www.ibm.com/topics/deep-learning}},
	shorttitle = {What is Deep Learning?},
	abstract = {Deep learning simulates our brain, helping systems learn to identify objects and perform complex tasks with increasing accuracy without human intervention.},
	urldate = {2023-10-21},
	langid = {english},
	keywords = {State of Art, TFM},
}

@online{noauthor_what_nodate-1,
	title = {What are Convolutional Neural Networks? {\textbar} {IBM}},
    note = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55}, \url{https://www.ibm.com/topics/convolutional-neural-networks}},
	shorttitle = {What are Convolutional Neural Networks?},
	abstract = {Learn how convolutional neural networks use three-dimensional data to for image classification and object recognition tasks.},
	urldate = {2023-10-21},
	langid = {english},
	keywords = {State of Art, TFM}
}

@article{wells_medical_1998,
	title = {A medical expert system approach using artificial neural networks for standardized treatment planning},
	volume = {41},
	ISSN = {0360-3016},
	DOI = {10.1016/S0360-3016(98)00035-2},
	pages = {173--182},
	number = {1},
	journal = {{INTERNATIONAL} {JOURNAL} {OF} {RADIATION} {ONCOLOGY} {BIOLOGY} {PHYSICS}},
	author = {Wells, {DM} and Niederer, J},
	date = {1998-04-01},
    year = {1998},
	keywords = {State of Art, TFM},
    note = {
        {ISSN: 0360-3016},
	   {DOI: 10.1016/S0360-3016(98)00035-2}
    },
}

@inproceedings{lee_machine_2009,
	title = {Machine Learning Framework for Classification in Medicine and Biology},
	volume = {5547},
	ISBN = {978-3-642-01928-9},
	series = {Lecture Notes in Computer Science},
	pages = {1--7},
	booktitle = {{INTEGRATION} {OF} {AI} {AND} {OR} {TECHNIQUES} {IN} {CONSTRAINT} {PROGRAMMING} {FOR} {COMBINATORIAL} {OPTIMIZATION} {PROBLEMS}, {PROCEEDINGS}},
	author = {Lee, Kva K.},
	editor = {{VanHoeve}, {WJ} and Hooker, {JN}},
	year = {2009},
	note = {{ISSN}: 0302-9743},
	keywords = {State of Art, TFM},
}

@article{garnavi_computer-aided_2012,
	title = {Computer-Aided Diagnosis of Melanoma Using Border- and Wavelet-Based Texture Analysis},
	volume = {16},
	ISSN = {1089-7771},
	DOI = {10.1109/TITB.2012.2212282},
	pages = {1239--1252},
	number = {6},
	journal = {{IEEE} {TRANSACTIONS} {ON} {INFORMATION} {TECHNOLOGY} {IN} {BIOMEDICINE}},
	author = {Garnavi, Rahil and Aldeen, Mohammad and Bailey, James},
	date = {2012-11},
    year= {2012},
	keywords = {State of Art, TFM},
}

@article{dreiseitl_comparison_2001,
	title = {A comparison of machine learning methods for the diagnosis of pigmented skin lesions},
	volume = {34},
	ISSN = {1532-0464},
	DOI = {10.1006/jbin.2001.1004},
	pages = {28--36},
	number = {1},
	journal = {{JOURNAL} {OF} {BIOMEDICAL} {INFORMATICS}},
	author = {Dreiseitl, S and Ohno-Machado, L and Kittler, H and Vinterbo, S and Billhardt, H and Binder, M},
	date = {2001-02},
    year = {2001},
	keywords = {State of Art, TFM},
    note = {
        {ISSN: 1532-0464},
	  {DOI: 10.1006/jbin.2001.1004},
    }
}

@inproceedings{dreiseitl_classifying_2000,
	title = {Classifying pigmented skin lesions with machine learning methods},
	ISBN = {1-85233-289-1},
	series = {{PERSPECTIVES} {IN} {NEURAL} {COMPUTING}},
	pages = {174--179},
	booktitle = {{ARTIFICIAL} {NEURAL} {NETWORKS} {IN} {MEDICINE} {AND} {BIOLOGY}},
	publisher = {Artificial Neural Networks Med \& Biol; Fdn Knowledge \& Competence Dev},
	author = {Dreiseitl, S and Kittler, H and Ganster, H and Binder, M},
	editor = {Malmgren, H and Borga, M and Niklasson, L},
	year = {2000},
	note = {{ISSN}: 1431-6854},
	keywords = {State of Art, TFM},
}

@article{celebi_automated_2014,
	title = {Automated Quantification of Clinically Significant Colors in Dermoscopy Images and Its Application to Skin Lesion Classification},
	volume = {8},
	ISSN = {1932-8184},
	DOI = {10.1109/JSYST.2014.2313671},
	pages = {980--984},
	number = {3},
	journal = {{IEEE} {SYSTEMS} {JOURNAL}},
	author = {Celebi, M. Emre and Zornberg, Azaria},
	date = {2014-09},
    year= {2014},
	keywords = {State of Art, TFM},
}

@article{beuscart_expert_1997,
	title = {An expert system for automatic analysis of whole body bone scintigraphy},
	volume = {21},
	ISSN = {0928-1258},
	pages = {56--62},
	number = {2},
	journal = {{MEDECINE} {NUCLEAIRE}},
	author = {Beuscart, R and Wartski, M and Bourguignon, {MH} and Foucher, C},
	year = {1997},
    note = {{ISSN: 0928-1258} 
            },
	keywords = {State of Art, TFM},
}

@article{abbas_melanoma_2013,
	title = {Melanoma recognition framework based on expert definition of {ABCD} for dermoscopic images},
	volume = {19},
	ISSN = {0909-752X},
	DOI = {10.1111/j.1600-0846.2012.00614.x},
	pages = {E93--E102},
	number = {1},
	journal = {{SKIN} {RESEARCH} {AND} {TECHNOLOGY}},
	author = {Abbas, Qaisar and Celebi, M. Emre and Fondon Garcia, Irene and Ahmad, Waqar},
	date = {2013-02},
    year= {2013},
	keywords = {State of Art, TFM},
}

@misc{le_building_2012,
	title = {Building high-level features using large scale unsupervised learning},
    note = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55}, \url{http://arxiv.org/abs/1112.6209}},
	abstract = {We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous {SGD} on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting with these learned features, we trained our network to obtain 15.8\% accuracy in recognizing 20,000 object categories from {ImageNet}, a leap of 70\% relative improvement over the previous state-of-the-art.},
	number = {{arXiv}:1112.6209},
	publisher = {{arXiv}},
	author = {Le, Quoc V. and Ranzato, Marc'Aurelio and Monga, Rajat and Devin, Matthieu and Chen, Kai and Corrado, Greg S. and Dean, Jeff and Ng, Andrew Y.},
	urldate = {2023-10-22},
	date = {2012-07-12},
    year= {2012},
	eprinttype = {arxiv},
	eprint = {1112.6209 [cs]},
	keywords = {Computer Science - Machine Learning},
}
%% Revisar x duplicado
@article{Le2011BuildingHF, 
    title={Building high-level features using large scale unsupervised learning}, 
    author={Quoc V. Le and Marc'Aurelio Ranzato and Rajat Monga and Matthieu Devin and Gregory S. Corrado and Kai Chen and Jeffrey Dean and A. Ng}, 
    journal={2013 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
    year={2011}, 
    pages={8595-8598}, 
    url={https://api.semanticscholar.org/CorpusID:206741597} }

@ARTICLE{7792699,
  author={Yu, Lequan and Chen, Hao and Dou, Qi and Qin, Jing and Heng, Pheng-Ann},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Automated Melanoma Recognition in Dermoscopy Images via Very Deep Residual Networks}, 
  year={2017},
  volume={36},
  number={4},
  pages={994-1004},
  DOI={10.1109/TMI.2016.2642839}}

@article{abuzaghleh_noninvasive_2015,
	title = {Noninvasive Real-Time Automated Skin Lesion Analysis System for Melanoma Early Detection and Prevention},
	volume = {3},
	ISSN = {2168-2372},
	DOI = {10.1109/JTEHM.2015.2419612},
	journal = {{IEEE} {JOURNAL} {OF} {TRANSLATIONAL} {ENGINEERING} {IN} {HEALTH} {AND} {MEDICINE}},
	author = {Abuzaghleh, Omar and Barkana, Buket D. and Faezipour, Miad},
	year = {2015},
	keywords = {State of Art, TFM},
    note = {
        {ISSN: 2168-2372}, 
	  {DOI: 10.1109/JTEHM.2015.2419612}
    },
}



@article{thamizhamuthu_deep_2023,
	title = {Deep Learning-Based Dermoscopic Image Classification System for Robust Skin Lesion Analysis},
	volume = {40},
	ISSN = {0765-0019},
	DOI = {10.18280/ts.400330},
	pages = {1145--1152},
	number = {3},
	journal = {{TRAITEMENT} {DU} {SIGNAL}},
	author = {Thamizhamuthu, Rajamanickam and Maniraj, Subramanian Pitchiah},
	date = {2023-06},
    year = {2023},
	keywords = {State of Art, TFM},
    note = {
       {ISSN: 0765-0019},
        {DOI: 10.18280/ts.400330}
    }
}


@article{chan_expert_1996,
	title = {An expert system for the detection of cervical cancer cells using knowledge-based image analyzer},
	volume = {8},
	ISSN = {0933-3657},
    note = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55},\url{https://www.sciencedirect.com/science/article/pii/0933365795000216},
	{DOI: \url{https://DOI.org/10.1016/0933-3657(95)00021-6}}            
           },
	abstract = {Analyzing for abnormalities of cell images in the cervix uteri provides a basis for reducing deaths and morbidity from cervical cancer through detection of potentially cancerous cells, provision of prompt advice and opportunities for follow-up and treatments. However, cytopathology is usually based on subjective interpretation of morphological features. Arbitrary criteria have to be devised for their classifications. Subjective interpretations of such criteria are likely to result in diagnostic shifts and consequently disagreement occurs between different interpreters. This article presents a novel approach to the composition of segmentation and diagnosis processes for biomedical image analysis. A prototype expert system has been developed to provide an objective and reliable tool to gynaecologists. Special image analyzing techniques are used and a set of knowledge sources is designed. The expert system employs a robust control strategy which minimizes the amount of domain-specific control knowledge. It has been proved to work effectively in the detection of cervical cancer.},
	pages = {67--90},
	number = {1},
	journal = {Artificial Intelligence in Medicine},
	author = {Chan, Samuel W. K. and Leung, K. S. and Wong, W. S. Felix},
	year = {1996},
    DOI = {https://DOI.org/10.1016/0933-3657(95)00021-6},
	keywords = {Cervical cancer, Expert system, Knowledge-based image analysis, Medical diagnosis, State of Art, TFM},
}

@article{rodrigues_new_2020,
	title = {A new approach for classification skin lesion based on transfer learning, deep learning, and {IoT} system},
	volume = {136},
    note ={{ISSN: 0167-8655}, 
          {DOI: 10.1016/j.patrec.2020.05.019}            
          }, 
	ISSN = {0167-8655},
	DOI = {10.1016/j.patrec.2020.05.019},
	pages = {8--15},
	journal = {{PATTERN} {RECOGNITION} {LETTERS}},
	author = {Rodrigues, Douglas de A. and Ivo, Roberto F. and Satapathy, Suresh Chandra and Wang, Shuihua and Hemanth, Jude and Reboucas Filho, Pedro P.},
	date = {2020-08},
    year= {2020},
	keywords = {State of Art, TFM, Transfer learning},
}

@inproceedings{wall_deep_2020,
	title = {Deep learning based melanoma diagnosis using dermoscopic images},
	volume = {12},
	ISBN = {978-981-122-333-4},
	series = {World Scientific Proceedings Series on Computer Engineering and Information Science},
	pages = {907--914},
	booktitle = {DEVELOPMENTS OF ARTIFICIAL INTELLIGENCE TECHNOLOGIES IN COMPUTATION AND ROBOTICS},
	publisher = {Fern Univ; {TH} Koln Univ Appl Sci; Univ Technol Sydney; {SW} Jiaotong Univ; Shunde Polytechn; Minnan Normal Univ; Natl Assoc Non Class Log \& Computat China},
	author = {Wall, Conor and Young, Fraser and Zhang, Li and Phillips, Emma-Jane and Jiang, Richard and Yu, Yonghong},
	editor = {Li, Z and Yuan, C and Lu, J and Kerre, {EE}},
	year = {2020},
	keywords = {State of Art, TFM, Transfer learning},
}

@inproceedings{abbes_deep_2021,
	title = {Deep Neural Networks for Melanoma Detection from Optical Standard Images using Transfer Learning},
	volume = {192},
	DOI = {10.1016/j.procs.2021.08.134},
	series = {Procedia Computer Science},
	pages = {1304--1312},
	booktitle = {KNOWLEDGE-BASED AND INTELLIGENT INFORMATION \& ENGINEERING SYSTEMS {KSE} 2021)},
	publisher = {{KES} Int},
	author = {Abbes, Wiem and Sellami, Dorra},
	editor = {Watrobski, J and Salabun, W and Toro, C and Zanni-Merk, C and Howlett, {RJ} and Jain, {LC}},
    year = {2021},
	note = {{ISSN}: 1877-0509},
	keywords = {State of Art, TFM, Transfer learning},
}

@inproceedings{georgakopoulos_detection_2017,
	title = {Detection of Malignant Melanomas in Dermoscopic Images Using Convolutional Neural Network with Transfer Learning},
	volume = {744},
	ISBN = {978-3-319-65172-9 978-3-319-65171-2},
	DOI = {10.1007/978-3-319-65172-9_34},
	series = {Communications in Computer and Information Science},
	pages = {404-414},
	booktitle = {{ENGINEERING} {APPLICATIONS} {OF} {NEURAL} {NETWORKS}, {EANN} 2017},
	author = {Georgakopoulos, V, S. and Kottari, K. and Delibasis, K. and Plagianakos, V. P. and Maglogiannis, I},
	editor = {Boracchi, G and Iliadis, L and Jayne, C and Likas, A},
    year = {2017},
	note = {{ISSN}: 1865-0929},
	keywords = {State of Art, TFM, Transfer learning},
}

@article{talavera-martinez_hair_2021,
	title = {Hair Segmentation and Removal in Dermoscopic Images Using Deep Learning},
	volume = {9},
	ISSN = {2169-3536},
	DOI = {10.1109/ACCESS.2020.3047258},
	pages = {2694--2704},
	journal = {{IEEE} {ACCESS}},
	author = {Talavera-Martinez, Lidia and Bibiloni, Pedro and Gonzalez-Hidalgo, Manuel},
	year = {2021},
	keywords = {State of Art, TFM, hair filter},
    note = {
        {ISSN: 2169-3536}, 
	   {DOI: 10.1109/ACCESS.2020.3047258}
    },
}

@article{bardou_hair_2022,
	title = {Hair removal in dermoscopy images using variational autoencoders},
	volume = {28},
	ISSN = {0909-752X},
	DOI = {10.1111/srt.13145},
	pages = {445--454},
	number = {3},
	journal = {{SKIN} {RESEARCH} {AND} {TECHNOLOGY}},
	author = {Bardou, Dalal and Bouaziz, Hamida and Lv, Laishui and Zhang, Ting},
	date = {2022-05},
    year= {2022},
	keywords = {State of Art, TFM, hair filter},
    note = {
        {ISSN: 0909-752X},
	  {DOI: 10.1111/srt.13145}
    }
}

@article{kaur_hairlines_2022,
	title = {Hairlines removal and low contrast enhancement of melanoma skin images using convolutional neural network with aggregation of contextual information},
	volume = {76},
	ISSN = {1746-8094},
	DOI = {10.1016/j.bspc.2022.103653},
	journal = {{BIOMEDICAL} {SIGNAL} {PROCESSING} {AND} {CONTROL}},
	author = {Kaur, Ranpreet and {GholamHosseini}, Hamid and Sinha, Roopak},
	date = {2022-07},
    year= {2022},
	keywords = {State of Art, TFM, hair filter},
    note = {
        {ISSN: 1746-8094}, 
	   {DOI: 10.1016/j.bspc.2022.103653}
    }
}

@misc{roy_effects_2023,
	title = {Effects of Degradations on Deep Neural Network Architectures},
    note = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55}, \url{http://arxiv.org/abs/1807.10108}},
	abstract = {Deep convolutional neural networks ({CNN}) have massively influenced recent advances in large-scale image classification. More recently, a dynamic routing algorithm with capsules (groups of neurons) has shown state-of-the-art recognition performance. However, the behavior of such networks in the presence of a degrading signal (noise) is mostly unexplored. An analytical study on different network architectures toward noise robustness is essential for selecting the appropriate model in a specific application scenario. This paper presents an extensive performance analysis of six deep architectures for image classification on six most common image degradation models. In this study, we have compared {VGG}-16, {VGG}-19, {ResNet}-50, Inception-v3, {MobileNet} and {CapsuleNet} architectures on Gaussian white, Gaussian color, salt-and-pepper, Gaussian blur, motion blur and {JPEG} compression noise models.},
	number = {{arXiv}:1807.10108},
	publisher = {{arXiv}},
	author = {Roy, Prasun and Ghosh, Subhankar and Bhattacharya, Saumik and Pal, Umapada},
	urldate = {2023-10-23},
	date = {2023-03-29},
    year= {2023},
	eprinttype = {arxiv},
	eprint = {1807.10108 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, State of Art, TFM},
}

@misc{laina_deeper_2016,
	title = {Deeper Depth Prediction with Fully Convolutional Residual Networks},
    note = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55}, \url{http://arxiv.org/abs/1606.00373}},
	abstract = {This paper addresses the problem of estimating the depth map of a scene given a single {RGB} image. We propose a fully convolutional architecture, encompassing residual learning, to model the ambiguous mapping between monocular images and depth maps. In order to improve the output resolution, we present a novel way to efficiently learn feature map up-sampling within the network. For optimization, we introduce the reverse Huber loss that is particularly suited for the task at hand and driven by the value distributions commonly present in depth maps. Our model is composed of a single architecture that is trained end-to-end and does not rely on post-processing techniques, such as {CRFs} or other additional refinement steps. As a result, it runs in real-time on images or videos. In the evaluation, we show that the proposed model contains fewer parameters and requires fewer training data than the current state of the art, while outperforming all approaches on depth estimation. Code and models are publicly available.},
	number = {{arXiv}:1606.00373},
	publisher = {{arXiv}},
	author = {Laina, Iro and Rupprecht, Christian and Belagiannis, Vasileios and Tombari, Federico and Navab, Nassir},
	urldate = {2023-10-23},
	date = {2016-09-19},
    year= {2016},
	eprinttype = {arxiv},
	eprint = {1606.00373 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, State of Art, TFM},
}

@misc{wong_what_2021,
	title = {What is Residual Connection?},
	note = {\url{https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55}},
	abstract = {A technique for training very deep neural networks},
	titleaddon = {Medium},
	author = {Wong, Wanshun},
	urldate = {2023-10-23},
	date = {2021-12-18},
        year= {2021},
	langid = {english},
	keywords = {State of Art},
}


@misc{shiri_comprehensive_nodate,
	title = {A Comprehensive Overview and Comparative Analysis on Deep Learning Models: {CNN}, {RNN}, {LSTM}, {GRU}},
	abstract = {Deep learning ({DL}) has emerged as a powerful subset of machine learning ({ML}) and artificial intelligence ({AI}), outperforming traditional {ML} methods, especially in handling unstructured and large datasets. Its impact spans across various domains, including speech recognition, healthcare, autonomous vehicles, cybersecurity, predictive analytics, and more. However, the complexity and dynamic nature of real-world problems present challenges in designing effective deep-learning models. Consequently, several deep learning models have been developed to address different problems and applications. In this article, we conduct a comprehensive survey of various deep learning models, including Convolutional Neural Networks ({CNNs}), Recurrent Neural Networks ({RNNs}), Generative Models, Deep Reinforcement Learning ({DRL}), and Deep Transfer Learning. We examine the structure, applications, benefits, and limitations of each model. Furthermore, we perform an analysis using three publicly available datasets: {IMDB}, {ARAS}, and Fruit-360. We compare the performance of six renowned deep learning models: {CNN}, Simple {RNN}, Long Short-Term Memory ({LSTM}), Bidirectional {LSTM}, Gated Recurrent Unit ({GRU}), and Bidirectional {GRU}.},
	author = {Shiri, Farhad Mortezapour and Perumal, Thinagaran and Mustapha, Norwati and Mohamed, Raihani},
    note= {{10.48550/arXiv.2305.17473}},
    year = {2023},
	langid = {english},
	keywords = {State of Art, TFM},
}

@article{chen_review_2021,
	title = {Review of Image Classification Algorithms Based on Convolutional Neural Networks},
	volume = {13},
	note = {{DOI: 10.3390/rs13224712}},
	number = {22},
	journal = {Remote sensing},
	author = {Chen, Leiyu and Li, Shaobo and Bai, Qiang and Yang, Jing and Jiang, Sanlong and Miao, Yanming},
	date = {2021-11},
	keywords = {State of Art, TFM},
    year = {2021}
}

@article{shorten_survey_2019,
	title = {A survey on Image Data Augmentation for Deep Learning},
	volume = {6},
	note = {{DOI: 10.1186/s40537-019-0197-0}},
	number = {1},
	journal = {Journal of big data},
	author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
	date = {2019-07-06},
    year= {2019},
	keywords = {State of Art, TFM, data augmentation},
}

%% Design and implementation
@misc{dataset_ref_1,
    author = {Tschandl P. and Rosendahl C.  and Kittler H.},
    title = {The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions},
    note = {\url{https://challenge.isic-archive.com/data/#2019}, 
           Sci. Data 5, 180161 DOI.10.1038/sdata.2018.161 (2018)},
    year= {2018},
}

@misc{dataset_ref_2,
    author = {Noel C. F. Codella and David Gutman and M. Emre Celebi and Brian Helba and Michael A. Marchetti and Stephen W. Dusza and Aadi Kalloo and Konstantinos Liopyris and Nabin Mishra and Harald Kittler and Allan Halpern},
    title = {Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)},
    year = {2017},
    note = {{arXiv:1710.05006}, \url{https://challenge.isic-archive.com/data/#2019}}
}

@misc{dataset_ref_3,
    author = {Marc Combalia  and Noel C. F. Codella  and Veronica Rotemberg and Brian Helba and Veronica Vilaplana and Ofer Reiter and Allan C. Halpern and Susana Puig and Josep Malvehy},
    title = {BCN20000: Dermoscopic Lesions in the Wild},
    year = {2019},
    note = {{arXiv:1908.02288}, \url{https://challenge.isic-archive.com/data/#2019}}
}

@misc{optimizers1,
    author = {Luis Velasco},
    title = {Optimizadores en redes neuronales profundas: un enfoque práctico},
    year = {2020},
    note = {{Medium}, \url{https://velascoluis.medium.com/optimizadores-en-redes-neuronales-profundas-un-enfoque-pr%C3%A1ctico-819b39a3eb5}}
}

@misc{SGDwithMomentum,
    author = {Vitaly Bushaev},
    title = {Stochastic Gradient Descent with momentum},
    year = {2017},
    note = {{Medium}, \url{https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d}}
}

%% EfficientNet
@misc{tan_efficientnet_2020,
	title = {{EfficientNet}: Rethinking Model Scaling for Convolutional Neural Networks},
	note = {{version: 5}, \url{http://arxiv.org/abs/1905.11946}},
	DOI = {10.48550/arXiv.1905.11946},
	shorttitle = {{EfficientNet}},
	abstract = {Convolutional Neural Networks ({ConvNets}) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up {MobileNets} and {ResNet}. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called {EfficientNets}, which achieve much better accuracy and efficiency than previous {ConvNets}. In particular, our {EfficientNet}-B7 achieves state-of-the-art 84.3\% top-1 accuracy on {ImageNet}, while being 8.4x smaller and 6.1x faster on inference than the best existing {ConvNet}. Our {EfficientNets} also transfer well and achieve state-of-the-art accuracy on {CIFAR}-100 (91.7\%), Flowers (98.8\%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
	number = {{arXiv}:1905.11946},
	publisher = {{arXiv}},
	author = {Tan, Mingxing},
	urldate = {2023-12-24},
	date = {2020-09-11},
	eprinttype = {arxiv},
	eprint = {1905.11946 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, {TFM}, building},
}

%% ResNet
@misc{medium_EfficientNet,
    author = {Vardan Agarwal},
    title = {Complete Architectural Details of all EfficienNet Models},
    year = {2020},
    note = {{Medium}, \url{https://towardsdatascience.com/complete-architectural-details-of-all-efficientnet-models-5fd5b736142}}
}

@misc{ResNet50_2015,
	title = {Deep Residual Learning for Image Recognition},
	note = {\url{http://arxiv.org/abs/1512.03385}},
	DOI = {10.48550/arXiv.1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the {ImageNet} dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than {VGG} nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the {ImageNet} test set. This result won the 1st place on the {ILSVRC} 2015 classification task. We also present analysis on {CIFAR}-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the {COCO} object detection dataset. Deep residual nets are foundations of our submissions to {ILSVRC} \& {COCO} 2015 competitions, where we also won the 1st places on the tasks of {ImageNet} detection, {ImageNet} localization, {COCO} detection, and {COCO} segmentation.},
	number = {{arXiv}:1512.03385},
	publisher = {{arXiv}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2023-12-26},
	date = {2015-12-10},
    year = {2015},
	eprinttype = {arxiv},
	eprint = {1512.03385 [cs]},
	keywords = {Building, Computer Science - Computer Vision and Pattern Recognition, {TFM}},
}
%% SMOTE
@misc{smote_belharar_enhancing_2023,
	title = {Enhancing Classification Accuracy for Imbalanced Image Data Using {SMOTE}},
	note = {\url{https://medium.com/@fatimazahra.belharar/enhancing-classification-accuracy-for-imbalanced-image-data-using-smote-41737783a720}},
	abstract = {In the world of data analysis and machine learning, not all datasets are created equal. One common challenge that often arises is dealing…},
	titleaddon = {Medium},
	author = {Belharar, Fatimazahra},
	urldate = {2023-12-27},
	date = {2023-06-07},
    year = 2023,
	langid = {english},
}

@misc{smote_maklin_synthetic_2022,
	title = {Synthetic Minority Over-sampling {TEchnique} ({SMOTE})},
	note = {\url{https://medium.com/@corymaklin/synthetic-minority-over-sampling-technique-smote-7d419696b88c}},
	abstract = {Synthetic Minority Over-sampling {TEchnique}, or {SMOTE} for short, is a preprocessing technique used to address a class imbalance in a…},
	titleaddon = {Medium},
	author = {Maklin, Cory},
	urldate = {2023-12-27},
	date = {2022-05-14},
    year = 2022,
	langid = {english},
	keywords = {{TFM} building},
}

@article{smote_JMLR:v18:16-365,
    author  = {Guillaume  Lema{{\^i}}tre and Fernando Nogueira and Christos K. Aridas},
    title   = {Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},
    journal = {Journal of Machine Learning Research},
    year    = {2017},
    volume  = {18},
    number  = {17},
    pages   = {1-5},
    note = {\url{http://jmlr.org/papers/v18/16-365.html}},
    keywords = {Building, {TFM}},
}

@misc{simonyan_very_2015,
	title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	note = {\url{http://arxiv.org/abs/1409.1556}},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our {ImageNet} Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing {ConvNet} models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	number = {{arXiv}:1409.1556},
	publisher = {{arXiv}},
	author = {Simonyan, Karen and Zisserman, Andrew},
	urldate = {2024-01-02},
	date = {2015-04-10},
    year = {2015},
	eprinttype = {arxiv},
	eprint = {1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Conclusion, {TFM}},
}

@misc{noauthor_papers_nodate,
	title = {Papers with Code - Vision Transformer Explained},
	note = {\url{https://paperswithcode.com/method/vision-transformer}},
	abstract = {The Vision Transformer, or {ViT}, is a model for image classification that employs a Transformer-like architecture over patches of the image.  An image is split into fixed-size patches, each of them are then linearly embedded, position embeddings are added, and the resulting sequence of vectors is fed to a standard Transformer encoder. In order to perform classification, the standard approach of adding an extra learnable “classification token” to the sequence is used.},
	urldate = {2024-01-02},
    year = {2024},
	langid = {english},
	keywords = {{TFM}, conclusion},
}

@misc{noauthor_resnet101_nodate,
	title = {resnet101 — Torchvision main documentation},
	note = {\url{https://pytorch.org/vision/main/models/generated/torchvision.models.resnet101.html}},
	urldate = {2024-01-02},
    year = {2024},
	keywords = {Conclusion, {TFM}},
}

@misc{melanoma_American_cancer_society,
	title = {What Is Melanoma Skin Cancer? {\textbar} What Is Melanoma?},
	url = {\url{https://www.cancer.org/cancer/types/melanoma-skin-cancer/about/what-is-melanoma.html}},
	shorttitle = {What Is Melanoma Skin Cancer?},
	abstract = {Melanoma is a form of skin cancer that begins in the melanocytes of the skin. Learn about melanoma here.},
	urldate = {2024-01-03},
	langid = {english},
	keywords = {Introduction, {TFM}},
    note = {
        {\url{https://www.cancer.org/cancer/types/melanoma-skin-cancer/about/what-is-melanoma.html}}
    }
}

@misc{basal_cell_American_cancer_society,
	title = {What are basal and Squamous cell skin canceers},
	url = {\url{https://www.cancer.org/cancer/types/basal-and-squamous-cell-skin-cancer/about/what-is-basal-and-squamous-cell.html}},
	urldate = {2024-01-03},
	langid = {english},
	keywords = {Introduction, {TFM}},
    note = {
        {\url{https://www.cancer.org/cancer/types/basal-and-squamous-cell-skin-cancer/about/what-is-basal-and-squamous-cell.html}}
    }
}

@misc{noauthor_melanocytic_2023,
	title = {Melanocytic nevus},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Melanocytic_nevus&oldid=1180791786},
	abstract = {A melanocytic nevus (also known as nevocytic nevus, nevus-cell nevus and commonly as a mole) is usually a noncancerous condition of pigment-producing skin cells. It is a type of melanocytic tumor that contains nevus cells. Some sources equate the term mole with "melanocytic nevus", but there are also sources that equate the term mole with any nevus form.The majority of moles appear during the first two decades of a person's life, with about one in every 100 babies being born with moles. Acquired moles are a form of benign neoplasm, while congenital moles, or congenital nevi, are considered a minor malformation or hamartoma and may be at a higher risk for melanoma. A mole can be either subdermal (under the skin) or a pigmented growth on the skin, formed mostly of a type of cell known as a melanocyte. The high concentration of the body's pigmenting agent, melanin, is responsible for their dark color. Moles are a member of the family of skin lesions known as nevi, occurring commonly in humans.},
	booktitle = {Wikipedia},
	urldate = {2024-01-03},
	date = {2023-10-18},
	langid = {english},
	note = {
        \url{https://en.wikipedia.org/w/index.php?title=Melanocytic_nevus&oldid=1180791786},
        {Rights: Creative Commons Attribution-{ShareAlike} License},
        {Page Version {ID}: 1180791786}
             }
}

@article{carmena-ramon_queratosis_2017,
	title = {Queratosis actínica: nuevo concepto y actualización terapéutica},
	volume = {49},
	issn = {02126567},
	url = {https://www.elsevier.es/es-revista-atencion-primaria-27-articulo-queratosis-actinica-nuevo-concepto-actualizacion-S0212656717301440},
	doi = {10.1016/j.aprim.2017.01.004},
	abstract = {La queratosis actínica ({QA}) es motivo de consulta frecuente tanto en atención primaria como en atención especializada. Supone el tercer o cuarto motivo más frecuente de consulta en dermatología, llegando a representar hasta un 5-6\% de los pacientes atendidos. Además, se ha observado que esta prevalencia ha ido en aumento en los últimos 10años, en comparación con otras dermatosis, y se prevé que seguirá aumentado por la mayor esperanza de vida y por los cambios de hábitos de exposición solar acontecidos desde mediados del siglo pasado. El objetivo de este artículo es actualizar los conceptos de {QA} y de campo de cancerización, y exponer las herramientas terapéuticas disponibles actualmente.},
	pages = {492--497},
	number = {8},
	journal = {Atención Primaria},
	shortjournal = {Atención Primaria},
	author = {Carmena-Ramón, Rafael and Mateu-Puchades, Almudena and Santos-Alarcón, Sergio and Lucas-Truyols, Sofía},
	year = {2017},
}


@misc{noauthor_queratosis_nodate,
	title = {Queratosis seborreica-Queratosis seborreica - Síntomas y causas},
	url = {https://www.mayoclinic.org/es/diseases-conditions/seborrheic-keratosis/symptoms-causes/syc-20353878},
	abstract = {Infórmate más sobre los síntomas y tratamientos de esta protuberancia común y no cancerosa que aparece gradualmente en la piel a medida que envejeces.},
	titleaddon = {Mayo Clinic},
	urldate = {2024-01-03},
	langid = {spanish},
	keywords = {{TFM}, introduction},
    note = {
        {Web site: Mayo Clinic},
        \url{https://www.mayoclinic.org/es/diseases-conditions/seborrheic-keratosis/symptoms-causes/syc-20353878},
    }
}

@article{hueso_dermatofibroma_2007,
	title = {Dermatofibroma gigante: descripción de un caso y revisión de la literatura},
	volume = {98},
	issn = {00017310},
	url = {https://www.actasdermo.org/es-dermatofibroma-gigante-descripcion-un-caso-articulo-13100619},
	abstract = {El dermatofibroma es una lesión muy frecuente que suele aparecer como un nódulo en dermis de lento crecimiento que afecta de forma predominante a las mujeres en los miembros inferiores. Se han descrito diferentes variedades clínicas. El dermatofibroma gigante se ha definido como una variante poco común de dermatofibroma de más de 5 cm que presenta las características histológicas típicas y un comportamiento biológico benigno. Presentamos el caso de un varón de 52 años que presentó un dermatofibroma gigante de 6 cm de diámetro en el hombro derecho y hacemos una revisión de los pocos casos de esta variedad descritos en la literatura.},
	pages = {121--124},
	number = {2},
	journal = {Actas Dermo-Sifiliográficas},
	shortjournal = {Actas Dermo-Sifiliográficas},
	author = {Hueso, L and Sanmartín, O and Alfaro-Rubio, A and Serra-Guillén, C and Martorell, A and Llombart, B and Requena, C and Nagore, E and Botella-Estrada, R and Guillén, C},
	year = {2007},
    note = {
        {ISSN: 00017310}
    }
}

@misc{noauthor_vascular_nodate,
	title = {Vascular Lesions of the Skin - Dermatologic Disorders},
	url = {https://www.msdmanuals.com/professional/dermatologic-disorders/benign-skin-tumors,-growths,-and-vascular-lesions/vascular-lesions-of-the-skin},
	abstract = {Vascular Lesions of the Skin - Etiology, pathophysiology, symptoms, signs, diagnosis \& prognosis from the {MSD} Manuals - Medical Professional Version.},
	titleaddon = {{MSD} Manual Professional Edition},
	urldate = {2024-01-03},
	langid = {english},
    note = {
        \url{https://www.msdmanuals.com/professional/dermatologic-disorders/benign-skin-tumors,-growths,-and-vascular-lesions/vascular-lesions-of-the-skin},
        {{MSD} Manual Professional Edition},
    }
}